{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# E-COMMERCE PRODUCT REVIEWS ANALYSIS - COMPLETE CAPSTONE ONE PROJECT\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import zipfile\n",
    "import io\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# NLP imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Deep Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Embedding, LSTM, GRU, Conv1D,\n",
    "                                     MaxPooling1D, Flatten, GlobalMaxPooling1D,\n",
    "                                     BatchNormalization, Bidirectional)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Imbalanced learning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# LLM and Embeddings\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 1: DATA LOADING AND PREPROCESSING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 1: DATA LOADING AND PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# File paths\n",
    "DATA_PATH = r\"C:\\Users\\edwar\\OneDrive\\Documents\\AI & Machine Learning Bootcamp\\amazon_reviews_us_Apparel_v1_00.csv.zip\"\n",
    "IMAGES_PATH = r\"C:\\Users\\edwar\\OneDrive\\Documents\\AI & Machine Learning Bootcamp\\Images Capstone.zip\"\n",
    "\n",
    "# Load dataset with correct method\n",
    "print(\"\\nLoading dataset...\")\n",
    "with zipfile.ZipFile(DATA_PATH, 'r') as z:\n",
    "    file_name = z.namelist()[0]\n",
    "    with z.open(file_name) as f:\n",
    "        content = f.read().decode('utf-8')\n",
    "        first_line = content.split('\\n')[0]\n",
    "        sep = '\\t' if '\\t' in first_line else ','\n",
    "        df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip', low_memory=False)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\n--- Dataset Info ---\")\n",
    "print(df.info())\n",
    "print(\"\\n--- Statistical Summary ---\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "print(missing_df[missing_df['Missing Values'] > 0].sort_values('Percentage', ascending=False))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DATA CLEANING\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Data Cleaning ---\")\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"Missing review_body before: {df_clean['review_body'].isnull().sum()}\")\n",
    "df_clean['review_body'] = df_clean['review_body'].fillna('')\n",
    "df_clean['review_headline'] = df_clean['review_headline'].fillna('')\n",
    "print(f\"Missing review_body after: {df_clean['review_body'].isnull().sum()}\")\n",
    "\n",
    "# Handle star_rating\n",
    "print(f\"Missing star_rating before: {df_clean['star_rating'].isnull().sum()}\")\n",
    "df_clean = df_clean.dropna(subset=['star_rating'])\n",
    "df_clean['star_rating'] = df_clean['star_rating'].astype(int)\n",
    "print(f\"Missing star_rating after: {df_clean['star_rating'].isnull().sum()}\")\n",
    "\n",
    "# Convert review_date to datetime\n",
    "df_clean['review_date'] = pd.to_datetime(df_clean['review_date'], errors='coerce')\n",
    "df_clean['review_year'] = df_clean['review_date'].dt.year\n",
    "df_clean['review_month'] = df_clean['review_date'].dt.month\n",
    "df_clean['review_day'] = df_clean['review_date'].dt.day\n",
    "df_clean['review_dayofweek'] = df_clean['review_date'].dt.dayofweek\n",
    "df_clean['review_quarter'] = df_clean['review_date'].dt.quarter\n",
    "print(f\"Date range: {df_clean['review_date'].min()} to {df_clean['review_date'].max()}\")\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)  \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  \n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\\-]', '', text)  \n",
    "    text = ' '.join(text.split())  \n",
    "    return text.strip()\n",
    "\n",
    "df_clean['review_body_clean'] = df_clean['review_body'].apply(clean_text)\n",
    "df_clean['review_headline_clean'] = df_clean['review_headline'].apply(clean_text)\n",
    "\n",
    "# Convert categorical to binary\n",
    "df_clean['verified_purchase_binary'] = df_clean['verified_purchase'].map({'Y': 1, 'N': 0})\n",
    "df_clean['vine_binary'] = df_clean['vine'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Handle votes\n",
    "df_clean['helpful_votes'] = pd.to_numeric(df_clean['helpful_votes'], errors='coerce').fillna(0).astype(int)\n",
    "df_clean['total_votes'] = pd.to_numeric(df_clean['total_votes'], errors='coerce').fillna(0).astype(int)\n",
    "df_clean['helpfulness_ratio'] = np.where(df_clean['total_votes'] > 0,\n",
    "                                          df_clean['helpful_votes'] / df_clean['total_votes'], 0)\n",
    "\n",
    "print(f\"\\nCleaned dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# EXPLORATORY DATA ANALYSIS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Exploratory Data Analysis ---\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nStar Rating Statistics:\")\n",
    "print(f\"Mean: {df_clean['star_rating'].mean():.4f}\")\n",
    "print(f\"Median: {df_clean['star_rating'].median():.4f}\")\n",
    "print(f\"Mode: {df_clean['star_rating'].mode()[0]}\")\n",
    "print(f\"Std: {df_clean['star_rating'].std():.4f}\")\n",
    "\n",
    "# Rating distribution plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "rating_counts = df_clean['star_rating'].value_counts().sort_index()\n",
    "axes[0].bar(rating_counts.index, rating_counts.values, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Star Rating')\n",
    "axes[0].set_ylabel('Number of Reviews')\n",
    "axes[0].set_title('Distribution of Star Ratings')\n",
    "for i, v in enumerate(rating_counts.values):\n",
    "    axes[0].text(rating_counts.index[i], v + 1000, f'{v:,}', ha='center', fontsize=9)\n",
    "\n",
    "axes[1].pie(rating_counts.values, labels=[f'{i} Star' for i in rating_counts.index],\n",
    "            autopct='%1.1f%%', startangle=90, colors=plt.cm.Blues(np.linspace(0.3, 0.9, 5)))\n",
    "axes[1].set_title('Percentage Distribution of Ratings')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "numerical_cols = ['star_rating', 'helpful_votes', 'total_votes', 'verified_purchase_binary',\n",
    "                  'helpfulness_ratio', 'vine_binary']\n",
    "correlation_matrix = df_clean[numerical_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True, linewidths=0.5, fmt='.3f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top reviewed products\n",
    "top_products = df_clean['product_id'].value_counts().head(15)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(top_products)), top_products.values, color='teal')\n",
    "plt.yticks(range(len(top_products)), top_products.index)\n",
    "plt.xlabel('Number of Reviews')\n",
    "plt.ylabel('Product ID')\n",
    "plt.title('Top 15 Most Reviewed Products')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Time series plot\n",
    "reviews_by_date = df_clean.groupby('review_date').size().reset_index(name='review_count')\n",
    "reviews_by_date = reviews_by_date.set_index('review_date').resample('M').sum().reset_index()\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reviews_by_date['review_date'], reviews_by_date['review_count'], color='steelblue', linewidth=1.5)\n",
    "plt.fill_between(reviews_by_date['review_date'], reviews_by_date['review_count'], alpha=0.3, color='steelblue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.title('Monthly Review Volume Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Box plot by verified purchase\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_clean.boxplot(column='star_rating', by='verified_purchase', figsize=(10, 6))\n",
    "plt.title('Star Rating Distribution by Verified Purchase Status')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('Verified Purchase')\n",
    "plt.ylabel('Star Rating')\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STATISTICAL ANALYSIS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Statistical Analysis ---\")\n",
    "\n",
    "# Hypothesis Testing\n",
    "verified_ratings = df_clean[df_clean['verified_purchase'] == 'Y']['star_rating']\n",
    "non_verified_ratings = df_clean[df_clean['verified_purchase'] == 'N']['star_rating']\n",
    "\n",
    "print(\"\\nHypothesis Test: Verified vs Non-Verified Purchases\")\n",
    "print(f\"Verified Mean: {verified_ratings.mean():.4f}, Count: {len(verified_ratings):,}\")\n",
    "print(f\"Non-Verified Mean: {non_verified_ratings.mean():.4f}, Count: {len(non_verified_ratings):,}\")\n",
    "\n",
    "statistic, p_value = stats.mannwhitneyu(verified_ratings, non_verified_ratings, alternative='greater')\n",
    "print(f\"Mann-Whitney U Test: U-statistic={statistic:,.0f}, P-value={p_value:.2e}\")\n",
    "print(f\"Conclusion: {'Verified purchases have significantly higher ratings' if p_value < 0.05 else 'No significant difference'}\")\n",
    "\n",
    "# Bayesian probability\n",
    "df_voted = df_clean[df_clean['total_votes'] >= 5].copy()\n",
    "df_voted['is_helpful'] = (df_voted['helpfulness_ratio'] > 0.5).astype(int)\n",
    "print(f\"\\nBayesian Analysis - P(Helpful): {df_voted['is_helpful'].mean():.4f}\")\n",
    "print(\"P(Helpful | Star Rating):\")\n",
    "for rating in range(1, 6):\n",
    "    subset = df_voted[df_voted['star_rating'] == rating]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"  Rating {rating}: {subset['is_helpful'].mean():.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# FEATURE ENGINEERING\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Feature Engineering ---\")\n",
    "\n",
    "df_clean['review_length'] = df_clean['review_body_clean'].str.len()\n",
    "df_clean['review_word_count'] = df_clean['review_body_clean'].str.split().str.len()\n",
    "df_clean['headline_length'] = df_clean['review_headline_clean'].str.len()\n",
    "\n",
    "print(f\"Review Length - Mean: {df_clean['review_length'].mean():.2f}, Max: {df_clean['review_length'].max()}\")\n",
    "\n",
    "# Review length vs helpfulness\n",
    "df_clean['length_bin'] = pd.cut(df_clean['review_length'],\n",
    "                                 bins=[0, 50, 100, 200, 500, 1000, float('inf')],\n",
    "                                 labels=['0-50', '50-100', '100-200', '200-500', '500-1000', '1000+'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "length_helpful = df_clean.groupby('length_bin')['helpfulness_ratio'].mean()\n",
    "length_helpful.plot(kind='bar', color='teal', edgecolor='black', ax=axes[0])\n",
    "axes[0].set_xlabel('Review Length')\n",
    "axes[0].set_ylabel('Avg Helpfulness Ratio')\n",
    "axes[0].set_title('Review Length vs Helpfulness')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "length_rating = df_clean.groupby('length_bin')['star_rating'].mean()\n",
    "length_rating.plot(kind='bar', color='coral', edgecolor='black', ax=axes[1])\n",
    "axes[1].set_xlabel('Review Length')\n",
    "axes[1].set_ylabel('Avg Star Rating')\n",
    "axes[1].set_title('Review Length vs Star Rating')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = ['total_votes', 'helpful_votes', 'review_length', 'review_word_count']\n",
    "df_clean[[f'{f}_scaled' for f in features_to_scale]] = scaler.fit_transform(df_clean[features_to_scale].fillna(0))\n",
    "\n",
    "print(\"\\nSection 1 Complete!\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 2: MACHINE LEARNING MODELS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 2: MACHINE LEARNING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample data for faster processing\n",
    "SAMPLE_SIZE = 100000\n",
    "df_sample = df_clean.sample(n=min(SAMPLE_SIZE, len(df_clean)), random_state=RANDOM_STATE)\n",
    "print(f\"\\nWorking with {len(df_sample):,} reviews\")\n",
    "\n",
    "# Advanced text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text_for_ml(text):\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "print(\"Preprocessing text...\")\n",
    "df_sample['review_processed'] = df_sample['review_body_clean'].apply(preprocess_text_for_ml)\n",
    "\n",
    "# TF-IDF\n",
    "print(\"Creating TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=5, max_df=0.95)\n",
    "tfidf_matrix = tfidf.fit_transform(df_sample['review_processed'].fillna(''))\n",
    "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Sentiment features\n",
    "print(\"Extracting sentiment features...\")\n",
    "df_sample['sentiment_polarity'] = df_sample['review_body_clean'].apply(\n",
    "    lambda x: TextBlob(str(x)).sentiment.polarity if x else 0)\n",
    "df_sample['sentiment_subjectivity'] = df_sample['review_body_clean'].apply(\n",
    "    lambda x: TextBlob(str(x)).sentiment.subjectivity if x else 0)\n",
    "\n",
    "# Visualize sentiment\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "df_sample.boxplot(column='sentiment_polarity', by='star_rating', ax=axes[0])\n",
    "axes[0].set_title('Sentiment Polarity by Star Rating')\n",
    "axes[0].set_xlabel('Star Rating')\n",
    "plt.suptitle('')\n",
    "\n",
    "sentiment_by_rating = df_sample.groupby('star_rating')['sentiment_polarity'].mean()\n",
    "sentiment_by_rating.plot(kind='bar', color='steelblue', edgecolor='black', ax=axes[1])\n",
    "axes[1].set_title('Average Sentiment Polarity by Star Rating')\n",
    "axes[1].set_xlabel('Star Rating')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Word clouds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "positive_text = ' '.join(df_sample[df_sample['star_rating'] >= 4]['review_processed'].dropna())\n",
    "wordcloud_pos = WordCloud(width=800, height=400, background_color='white',\n",
    "                          colormap='Greens', max_words=100).generate(positive_text if positive_text else 'empty')\n",
    "axes[0].imshow(wordcloud_pos, interpolation='bilinear')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Word Cloud: Positive Reviews (4-5 Stars)', fontsize=14)\n",
    "\n",
    "negative_text = ' '.join(df_sample[df_sample['star_rating'] <= 2]['review_processed'].dropna())\n",
    "wordcloud_neg = WordCloud(width=800, height=400, background_color='white',\n",
    "                          colormap='Reds', max_words=100).generate(negative_text if negative_text else 'empty')\n",
    "axes[1].imshow(wordcloud_neg, interpolation='bilinear')\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Word Cloud: Negative Reviews (1-2 Stars)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PREPARE FEATURES FOR ML\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Preparing Features ---\")\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = ['review_length', 'review_word_count', 'sentiment_polarity',\n",
    "                      'sentiment_subjectivity', 'verified_purchase_binary', 'helpful_votes', 'total_votes']\n",
    "X_numerical = df_sample[numerical_features].fillna(0).values\n",
    "\n",
    "# Combine with TF-IDF\n",
    "X_combined = hstack([tfidf_matrix, X_numerical])\n",
    "print(f\"Combined Feature Matrix Shape: {X_combined.shape}\")\n",
    "\n",
    "# Target variables\n",
    "y_regression = df_sample['star_rating'].values\n",
    "\n",
    "def categorize_rating(rating):\n",
    "    if rating >= 4: return 'positive'\n",
    "    elif rating == 3: return 'neutral'\n",
    "    else: return 'negative'\n",
    "\n",
    "df_sample['sentiment_class'] = df_sample['star_rating'].apply(categorize_rating)\n",
    "y_classification = df_sample['sentiment_class'].values\n",
    "print(f\"Classification Target Distribution:\\n{pd.Series(y_classification).value_counts()}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_combined, y_regression, test_size=0.2, random_state=RANDOM_STATE)\n",
    "_, _, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_combined, y_classification, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,}, Test set: {X_test.shape[0]:,}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# REGRESSION MODELS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Regression Models ---\")\n",
    "\n",
    "def evaluate_regression(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Train R2': r2_score(y_train, y_pred_train),\n",
    "        'Test R2': r2_score(y_test, y_pred_test),\n",
    "        'Test RMSE': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        'Test MAE': mean_absolute_error(y_test, y_pred_test)\n",
    "    }\n",
    "    return results, y_pred_test\n",
    "\n",
    "# Linear Regression\n",
    "lr_results, lr_pred = evaluate_regression(LinearRegression(), X_train, X_test, y_train_reg, y_test_reg, 'Linear Regression')\n",
    "print(f\"Linear Regression - R2: {lr_results['Test R2']:.4f}, RMSE: {lr_results['Test RMSE']:.4f}\")\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_results, ridge_pred = evaluate_regression(Ridge(alpha=1.0), X_train, X_test, y_train_reg, y_test_reg, 'Ridge Regression')\n",
    "print(f\"Ridge Regression - R2: {ridge_results['Test R2']:.4f}, RMSE: {ridge_results['Test RMSE']:.4f}\")\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_results, lasso_pred = evaluate_regression(Lasso(alpha=0.01, max_iter=1000), X_train, X_test, y_train_reg, y_test_reg, 'Lasso Regression')\n",
    "print(f\"Lasso Regression - R2: {lasso_results['Test R2']:.4f}, RMSE: {lasso_results['Test RMSE']:.4f}\")\n",
    "\n",
    "regression_results = pd.DataFrame([lr_results, ridge_results, lasso_results])\n",
    "print(\"\\nRegression Models Comparison:\")\n",
    "print(regression_results.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for ax, (name, pred) in zip(axes, [('Linear', lr_pred), ('Ridge', ridge_pred), ('Lasso', lasso_pred)]):\n",
    "    ax.scatter(y_test_reg, pred, alpha=0.3, s=10)\n",
    "    ax.plot([1, 5], [1, 5], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_title(f'{name} Regression')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CLASSIFICATION MODELS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Classification Models ---\")\n",
    "\n",
    "def evaluate_classification(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    return results, y_pred, model\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg_results, log_reg_pred, log_reg_model = evaluate_classification(\n",
    "    LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    X_train, X_test, y_train_clf, y_test_clf, 'Logistic Regression')\n",
    "print(f\"Logistic Regression - Accuracy: {log_reg_results['Accuracy']:.4f}, F1: {log_reg_results['F1-Score']:.4f}\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_results, dt_pred, _ = evaluate_classification(\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=RANDOM_STATE),\n",
    "    X_train, X_test, y_train_clf, y_test_clf, 'Decision Tree')\n",
    "print(f\"Decision Tree - Accuracy: {dt_results['Accuracy']:.4f}, F1: {dt_results['F1-Score']:.4f}\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_results, rf_pred, _ = evaluate_classification(rf_model, X_train, X_test, y_train_clf, y_test_clf, 'Random Forest')\n",
    "print(f\"Random Forest - Accuracy: {rf_results['Accuracy']:.4f}, F1: {rf_results['F1-Score']:.4f}\")\n",
    "\n",
    "# Naive Bayes (TF-IDF only)\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(tfidf_matrix, y_classification, test_size=0.2, random_state=RANDOM_STATE)\n",
    "nb_results, nb_pred, _ = evaluate_classification(\n",
    "    MultinomialNB(), X_train_tfidf, X_test_tfidf, y_train_clf, y_test_clf, 'Naive Bayes')\n",
    "print(f\"Naive Bayes - Accuracy: {nb_results['Accuracy']:.4f}, F1: {nb_results['F1-Score']:.4f}\")\n",
    "\n",
    "# Classification report for best model\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test_clf, rf_pred))\n",
    "\n",
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "for ax, (name, pred) in zip(axes.flatten(),\n",
    "    [('Logistic Regression', log_reg_pred), ('Decision Tree', dt_pred),\n",
    "     ('Random Forest', rf_pred), ('Naive Bayes', nb_pred)]):\n",
    "    cm = confusion_matrix(y_test_clf, pred, labels=['negative', 'neutral', 'positive'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Neg', 'Neu', 'Pos'], yticklabels=['Neg', 'Neu', 'Pos'])\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HANDLING IMBALANCED DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Handling Imbalanced Data ---\")\n",
    "\n",
    "# Class weighting\n",
    "rf_weighted = RandomForestClassifier(n_estimators=100, max_depth=15, class_weight='balanced',\n",
    "                                      random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_weighted.fit(X_train, y_train_clf)\n",
    "y_pred_weighted = rf_weighted.predict(X_test)\n",
    "print(f\"RF with Class Weighting - Accuracy: {accuracy_score(y_test_clf, y_pred_weighted):.4f}, F1: {f1_score(y_test_clf, y_pred_weighted, average='weighted'):.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ENSEMBLE LEARNING\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Ensemble Learning ---\")\n",
    "\n",
    "# AdaBoost\n",
    "ada_results, ada_pred, _ = evaluate_classification(\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    X_train, X_test, y_train_clf, y_test_clf, 'AdaBoost')\n",
    "print(f\"AdaBoost - Accuracy: {ada_results['Accuracy']:.4f}, F1: {ada_results['F1-Score']:.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_results, gb_pred, _ = evaluate_classification(\n",
    "    GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=RANDOM_STATE),\n",
    "    X_train, X_test, y_train_clf, y_test_clf, 'Gradient Boosting')\n",
    "print(f\"Gradient Boosting - Accuracy: {gb_results['Accuracy']:.4f}, F1: {gb_results['F1-Score']:.4f}\")\n",
    "\n",
    "# Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=50, max_depth=10, random_state=RANDOM_STATE)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=RANDOM_STATE))\n",
    "    ], voting='soft')\n",
    "voting_results, voting_pred, _ = evaluate_classification(voting_clf, X_train, X_test, y_train_clf, y_test_clf, 'Voting Classifier')\n",
    "print(f\"Voting Classifier - Accuracy: {voting_results['Accuracy']:.4f}, F1: {voting_results['F1-Score']:.4f}\")\n",
    "\n",
    "# Final comparison\n",
    "all_results = pd.DataFrame([log_reg_results, dt_results, rf_results, nb_results, ada_results, gb_results, voting_results])\n",
    "all_results = all_results.sort_values('F1-Score', ascending=False)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASSIFICATION MODELS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(all_results.to_string(index=False))\n",
    "\n",
    "print(\"\\nSection 2 Complete!\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 3: DEEP LEARNING MODELS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 3: DEEP LEARNING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare text data for deep learning\n",
    "MAX_WORDS = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "tokenizer_dl = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer_dl.fit_on_texts(df_sample['review_processed'])\n",
    "sequences = tokenizer_dl.texts_to_sequences(df_sample['review_processed'])\n",
    "X_padded = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Vocabulary Size: {len(tokenizer_dl.word_index)}\")\n",
    "print(f\"Padded Sequences Shape: {X_padded.shape}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_sample['sentiment_class'])\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "\n",
    "# Split for deep learning\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(\n",
    "    X_padded, y_categorical, test_size=0.2, random_state=RANDOM_STATE)\n",
    "print(f\"DL Training set: {X_train_dl.shape}, Test set: {X_test_dl.shape}\")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DNN MODEL\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Training DNN Model ---\")\n",
    "\n",
    "dnn_model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_dnn = dnn_model.fit(X_train_dl, y_train_dl, epochs=10, batch_size=128,\n",
    "                            validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "\n",
    "dnn_loss, dnn_accuracy = dnn_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "print(f\"DNN Test Accuracy: {dnn_accuracy:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# LSTM MODEL\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Training LSTM Model ---\")\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_lstm = lstm_model.fit(X_train_dl, y_train_dl, epochs=10, batch_size=128,\n",
    "                              validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "print(f\"LSTM Test Accuracy: {lstm_accuracy:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CNN MODEL\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Training CNN Model ---\")\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_cnn = cnn_model.fit(X_train_dl, y_train_dl, epochs=10, batch_size=128,\n",
    "                            validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "print(f\"CNN Test Accuracy: {cnn_accuracy:.4f}\")\n",
    "\n",
    "# Deep Learning comparison\n",
    "dl_results = pd.DataFrame({\n",
    "    'Model': ['DNN', 'LSTM', 'CNN'],\n",
    "    'Test Accuracy': [dnn_accuracy, lstm_accuracy, cnn_accuracy],\n",
    "    'Test Loss': [dnn_loss, lstm_loss, cnn_loss]\n",
    "}).sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DEEP LEARNING MODELS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(dl_results.to_string(index=False))\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for ax, (name, history) in zip(axes, [('DNN', history_dnn), ('LSTM', history_lstm), ('CNN', history_cnn)]):\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax.set_title(f'{name} Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# DL comparison bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.8, 3))\n",
    "bars = plt.bar(['DNN', 'LSTM', 'CNN'], [dnn_accuracy, lstm_accuracy, cnn_accuracy], color=colors, edgecolor='black')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Deep Learning Models Comparison')\n",
    "plt.ylim(0, 1)\n",
    "for bar, acc in zip(bars, [dnn_accuracy, lstm_accuracy, cnn_accuracy]):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{acc:.4f}', ha='center', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSection 3 Complete!\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 4: LLMs AND RETRIEVAL-BASED AI\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 4: LLMs AND RETRIEVAL-BASED AI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare product data\n",
    "product_reviews = df_sample.groupby('product_id').agg({\n",
    "    'review_body_clean': lambda x: ' | '.join(x.head(5)),\n",
    "    'star_rating': 'mean',\n",
    "    'review_headline_clean': lambda x: ' | '.join(x.head(3))\n",
    "}).reset_index()\n",
    "product_reviews.columns = ['product_id', 'combined_reviews', 'avg_rating', 'combined_headlines']\n",
    "product_reviews = product_reviews.head(1000)\n",
    "print(f\"Products for LLM analysis: {len(product_reviews)}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TRANSFORMER SENTIMENT ANALYSIS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Transformer Sentiment Analysis ---\")\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",\n",
    "                              model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                              truncation=True, max_length=512)\n",
    "\n",
    "sample_reviews = df_sample['review_body_clean'].head(20).tolist()\n",
    "transformer_sentiments = []\n",
    "for review in sample_reviews:\n",
    "    if review and len(review) > 0:\n",
    "        try:\n",
    "            result = sentiment_pipeline(review[:512])[0]\n",
    "            transformer_sentiments.append(result)\n",
    "        except:\n",
    "            transformer_sentiments.append({'label': 'NEUTRAL', 'score': 0.5})\n",
    "    else:\n",
    "        transformer_sentiments.append({'label': 'NEUTRAL', 'score': 0.5})\n",
    "\n",
    "print(\"Sample Transformer Results:\")\n",
    "for i in range(3):\n",
    "    print(f\"  Review: {sample_reviews[i][:80]}...\")\n",
    "    print(f\"  Sentiment: {transformer_sentiments[i]}\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SUMMARIZATION\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Text Summarization ---\")\n",
    "\n",
    "try:\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", truncation=True)\n",
    "    sample_text = product_reviews['combined_reviews'].iloc[0]\n",
    "    if len(sample_text) > 100:\n",
    "        summary = summarizer(sample_text[:1024], max_length=100, min_length=30, do_sample=False)\n",
    "        print(f\"Original (truncated): {sample_text[:300]}...\")\n",
    "        print(f\"Summary: {summary[0]['summary_text']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Summarization skipped: {e}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VECTOR EMBEDDINGS AND SEMANTIC SEARCH\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Vector Embeddings & Semantic Search ---\")\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "review_texts = product_reviews['combined_reviews'].tolist()\n",
    "review_embeddings = embedding_model.encode(review_texts, show_progress_bar=True)\n",
    "print(f\"Embeddings shape: {review_embeddings.shape}\")\n",
    "\n",
    "# Build FAISS index\n",
    "dimension = review_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(review_embeddings.astype('float32'))\n",
    "print(f\"FAISS index created with {index.ntotal} vectors\")\n",
    "\n",
    "# Semantic search function\n",
    "def semantic_search(query, top_k=5):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    distances, indices = index.search(query_embedding.astype('float32'), top_k)\n",
    "    results = []\n",
    "    for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "        results.append({\n",
    "            'rank': i + 1,\n",
    "            'product_id': product_reviews.iloc[idx]['product_id'],\n",
    "            'avg_rating': product_reviews.iloc[idx]['avg_rating'],\n",
    "            'distance': dist,\n",
    "            'reviews': product_reviews.iloc[idx]['combined_reviews'][:200]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Example search\n",
    "query = \"comfortable and fits well\"\n",
    "results = semantic_search(query)\n",
    "print(f\"\\nSearch Query: '{query}'\")\n",
    "print(\"Top Results:\")\n",
    "for r in results[:3]:\n",
    "    print(f\"  Rank {r['rank']}: Product {r['product_id']}, Rating: {r['avg_rating']:.2f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# RAG IMPLEMENTATION\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- RAG Implementation ---\")\n",
    "\n",
    "def create_rag_prompt(query, retrieved_contexts, max_contexts=3):\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Product {i+1} (Rating: {ctx['avg_rating']:.1f}):\\n{ctx['reviews']}\"\n",
    "        for i, ctx in enumerate(retrieved_contexts[:max_contexts])\n",
    "    ])\n",
    "    prompt = f\"\"\"Based on the following customer reviews, answer the question.\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "query = \"What do customers say about product quality?\"\n",
    "contexts = semantic_search(query, top_k=3)\n",
    "rag_prompt = create_rag_prompt(query, contexts)\n",
    "print(\"Generated RAG Prompt:\")\n",
    "print(rag_prompt[:500] + \"...\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# FAKE REVIEW DETECTION\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Fake Review Detection ---\")\n",
    "\n",
    "def extract_spam_features(df):\n",
    "    features_df = df.copy()\n",
    "    features_df['review_length'] = features_df['review_body_clean'].str.len()\n",
    "    features_df['word_count'] = features_df['review_body_clean'].str.split().str.len()\n",
    "    features_df['avg_word_length'] = features_df['review_length'] / (features_df['word_count'] + 1)\n",
    "    features_df['uppercase_ratio'] = features_df['review_body'].apply(\n",
    "        lambda x: sum(1 for c in str(x) if c.isupper()) / (len(str(x)) + 1))\n",
    "    features_df['exclamation_count'] = features_df['review_body'].str.count('!')\n",
    "    features_df['extreme_rating'] = features_df['star_rating'].isin([1, 5]).astype(int)\n",
    "    features_df['not_verified'] = (features_df['verified_purchase'] == 'N').astype(int)\n",
    "    return features_df\n",
    "\n",
    "df_spam = extract_spam_features(df_sample)\n",
    "spam_features = ['review_length', 'word_count', 'avg_word_length', 'uppercase_ratio',\n",
    "                 'exclamation_count', 'extreme_rating', 'not_verified']\n",
    "\n",
    "X_spam = df_spam[spam_features].fillna(0)\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "spam_predictions = iso_forest.fit_predict(X_spam)\n",
    "df_spam['is_potential_spam'] = (spam_predictions == -1).astype(int)\n",
    "\n",
    "print(f\"Potential spam reviews detected: {df_spam['is_potential_spam'].sum():,}\")\n",
    "print(f\"Percentage: {df_spam['is_potential_spam'].mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\nSpam vs Legitimate Comparison:\")\n",
    "comparison = df_spam.groupby('is_potential_spam')[spam_features].mean()\n",
    "comparison.index = ['Legitimate', 'Potential Spam']\n",
    "print(comparison.T)\n",
    "\n",
    "print(\"\\nSection 4 Complete!\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E-COMMERCE REVIEW ANALYSIS - CAPSTONE PROJECT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET OVERVIEW:\")\n",
    "print(f\"   Total Reviews Processed: {len(df_clean):,}\")\n",
    "print(f\"   Unique Products: {df_clean['product_id'].nunique():,}\")\n",
    "print(f\"   Date Range: {df_clean['review_date'].min()} to {df_clean['review_date'].max()}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ BEST PERFORMING MODELS:\")\n",
    "print(\"\\n   Machine Learning (Classification):\")\n",
    "best_ml = all_results.iloc[0]\n",
    "print(f\"      Model: {best_ml['Model']}\")\n",
    "print(f\"      F1-Score: {best_ml['F1-Score']:.4f}\")\n",
    "\n",
    "print(\"\\n   Deep Learning (Classification):\")\n",
    "best_dl = dl_results.iloc[0]\n",
    "print(f\"      Model: {best_dl['Model']}\")\n",
    "print(f\"      Accuracy: {best_dl['Test Accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ KEY INSIGHTS:\")\n",
    "print(f\"   â€¢ Average Star Rating: {df_clean['star_rating'].mean():.2f}\")\n",
    "print(f\"   â€¢ Verified Purchases: {(df_clean['verified_purchase']=='Y').mean()*100:.1f}%\")\n",
    "print(f\"   â€¢ Potential Spam Reviews: {df_spam['is_potential_spam'].mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\nâœ… CAPABILITIES DEVELOPED:\")\n",
    "print(\"   â€¢ Sentiment Analysis (ML & Deep Learning)\")\n",
    "print(\"   â€¢ Star Rating Prediction\")\n",
    "print(\"   â€¢ Fake Review Detection\")\n",
    "print(\"   â€¢ Review Summarization (LLM)\")\n",
    "print(\"   â€¢ Semantic Product Search (RAG)\")\n",
    "\n",
    "# Save models\n",
    "print(\"\\nðŸ’¾ SAVING MODELS...\")\n",
    "joblib.dump(rf_model, 'sentiment_rf_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "dnn_model.save('sentiment_dnn_model.keras')\n",
    "lstm_model.save('sentiment_lstm_model.keras')\n",
    "cnn_model.save('sentiment_cnn_model.keras')\n",
    "print(\"   All models saved successfully!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CAPSTONE PROJECT COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
